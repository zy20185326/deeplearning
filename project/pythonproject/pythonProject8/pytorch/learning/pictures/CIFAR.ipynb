{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-29T08:08:46.956537Z",
     "start_time": "2024-08-29T08:08:41.440484Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn as nn\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch import optim"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T16:09:33.421528Z",
     "start_time": "2024-08-28T16:09:33.402797Z"
    }
   },
   "cell_type": "code",
   "source": "datapath='F:\\\\deeplearning\\\\datasets'",
   "id": "deaab6d1bf82d413",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T16:09:35.913966Z",
     "start_time": "2024-08-28T16:09:35.108985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#下载，train=True是训练集，False是验证集\n",
    "cifar10=datasets.CIFAR10(datapath,train=True,download=False)\n",
    "cifar10_val=datasets.CIFAR10(datapath,train=False,download=False)"
   ],
   "id": "7486b9db5ffcbbca",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T16:01:59.663938Z",
     "start_time": "2024-08-28T16:01:59.659936Z"
    }
   },
   "cell_type": "code",
   "source": "len(cifar10)",
   "id": "a46e33ba365a5e6d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T10:23:20.866047Z",
     "start_time": "2024-08-28T10:23:20.852949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#输出一个python image Library图像和类型\n",
    "img1,label=cifar10[99]"
   ],
   "id": "e7da8241e065477e",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T10:23:46.630616Z",
     "start_time": "2024-08-28T10:23:46.586608Z"
    }
   },
   "cell_type": "code",
   "source": "img1",
   "id": "75997e86b9253bb5",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Image' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[32], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mimg1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'Image' object has no attribute 'shape'"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T10:23:23.246596Z",
     "start_time": "2024-08-28T10:23:23.232593Z"
    }
   },
   "cell_type": "code",
   "source": "img1,label",
   "id": "71b365e266b61e92",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=RGB size=32x32>, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T08:35:45.087791Z",
     "start_time": "2024-08-27T08:35:45.069786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img,label=cifar10[299]\n",
    "img,label"
   ],
   "id": "5ea14f1ffd544c86",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=RGB size=32x32>, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T08:37:31.051634Z",
     "start_time": "2024-08-27T08:37:30.946518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.imshow(img1)\n",
    "plt.show()"
   ],
   "id": "8d7d1ab3e5f0f09c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T03:47:01.354501Z",
     "start_time": "2024-08-28T03:47:01.341722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "totensor=transforms.ToTensor()\n",
    "imgc = totensor(img1)\n",
    "imgc.shape"
   ],
   "id": "82136a6def215d10",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T16:09:40.668747Z",
     "start_time": "2024-08-28T16:09:40.358652Z"
    }
   },
   "cell_type": "code",
   "source": "tensor_cifar10=datasets.CIFAR10(datapath,train=False,download=False,transform=transforms.ToTensor())",
   "id": "f2f20617479cf9d6",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T03:47:19.153965Z",
     "start_time": "2024-08-28T03:47:17.624845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "imgs=torch.stack([img for img ,_ in tensor_cifar10],dim=3)\n",
    "imgs.shape"
   ],
   "id": "52503608ead486f1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32, 10000])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T11:57:04.629869Z",
     "start_time": "2024-08-27T11:57:04.620790Z"
    }
   },
   "cell_type": "code",
   "source": "imgs.view(3,-1).shape",
   "id": "71158946d53359f2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10240000])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4942, 0.4851, 0.4504])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13,
   "source": "imgs.view(3,-1).mean(dim=1)",
   "id": "9acbf1fcec7733d2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2467, 0.2429, 0.2616])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14,
   "source": "imgs.view(3,-1).std(dim=1)",
   "id": "c3875d337956005b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T03:51:19.737662Z",
     "start_time": "2024-08-28T03:51:19.717448Z"
    }
   },
   "cell_type": "code",
   "source": "a=imgs.view(3,-1).mean(dim=1)",
   "id": "3782ff09521cdb81",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T03:51:21.879503Z",
     "start_time": "2024-08-28T03:51:21.651949Z"
    }
   },
   "cell_type": "code",
   "source": "b=imgs.view(3,-1).std(dim=1)",
   "id": "eda197f9db8ba3f",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T16:09:44.112736Z",
     "start_time": "2024-08-28T16:09:43.628559Z"
    }
   },
   "cell_type": "code",
   "source": "transforms_cifar10= datasets.CIFAR10(datapath,train=True,download=False,transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize(a, b)]))    ",
   "id": "8b8708156955bedb",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T03:52:04.084118Z",
     "start_time": "2024-08-28T03:52:04.062733Z"
    }
   },
   "cell_type": "code",
   "source": "imgt,_ = tensor_cifar10[99]",
   "id": "f9256097fe501bad",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T03:53:51.283890Z",
     "start_time": "2024-08-28T03:53:50.739123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.imshow(imgt.permute(1,2,0))\n",
    "plt.show()"
   ],
   "id": "913c8f179cd3c6c4",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (3, 32, 32) for image data",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimshow\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimgt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m plt\u001B[38;5;241m.\u001B[39mshow()\n",
      "File \u001B[1;32mE:\\condaenvs\\pytorch\\lib\\site-packages\\matplotlib\\pyplot.py:2695\u001B[0m, in \u001B[0;36mimshow\u001B[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001B[0m\n\u001B[0;32m   2689\u001B[0m \u001B[38;5;129m@_copy_docstring_and_deprecators\u001B[39m(Axes\u001B[38;5;241m.\u001B[39mimshow)\n\u001B[0;32m   2690\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mimshow\u001B[39m(\n\u001B[0;32m   2691\u001B[0m         X, cmap\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, norm\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m, aspect\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, interpolation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   2692\u001B[0m         alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, vmin\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, vmax\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, origin\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, extent\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   2693\u001B[0m         interpolation_stage\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, filternorm\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, filterrad\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4.0\u001B[39m,\n\u001B[0;32m   2694\u001B[0m         resample\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, url\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m-> 2695\u001B[0m     __ret \u001B[38;5;241m=\u001B[39m \u001B[43mgca\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimshow\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2696\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcmap\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcmap\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnorm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnorm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maspect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maspect\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2697\u001B[0m \u001B[43m        \u001B[49m\u001B[43minterpolation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minterpolation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvmin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvmin\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2698\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvmax\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvmax\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morigin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morigin\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2699\u001B[0m \u001B[43m        \u001B[49m\u001B[43minterpolation_stage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minterpolation_stage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2700\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilternorm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilternorm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilterrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilterrad\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresample\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresample\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2701\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m}\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2702\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2703\u001B[0m     sci(__ret)\n\u001B[0;32m   2704\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m __ret\n",
      "File \u001B[1;32mE:\\condaenvs\\pytorch\\lib\\site-packages\\matplotlib\\__init__.py:1475\u001B[0m, in \u001B[0;36m_preprocess_data.<locals>.inner\u001B[1;34m(ax, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1472\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m   1473\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(ax, \u001B[38;5;241m*\u001B[39margs, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m   1474\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1475\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43max\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mmap\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msanitize_sequence\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1477\u001B[0m     bound \u001B[38;5;241m=\u001B[39m new_sig\u001B[38;5;241m.\u001B[39mbind(ax, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1478\u001B[0m     auto_label \u001B[38;5;241m=\u001B[39m (bound\u001B[38;5;241m.\u001B[39marguments\u001B[38;5;241m.\u001B[39mget(label_namer)\n\u001B[0;32m   1479\u001B[0m                   \u001B[38;5;129;01mor\u001B[39;00m bound\u001B[38;5;241m.\u001B[39mkwargs\u001B[38;5;241m.\u001B[39mget(label_namer))\n",
      "File \u001B[1;32mE:\\condaenvs\\pytorch\\lib\\site-packages\\matplotlib\\axes\\_axes.py:5663\u001B[0m, in \u001B[0;36mAxes.imshow\u001B[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001B[0m\n\u001B[0;32m   5655\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_aspect(aspect)\n\u001B[0;32m   5656\u001B[0m im \u001B[38;5;241m=\u001B[39m mimage\u001B[38;5;241m.\u001B[39mAxesImage(\u001B[38;5;28mself\u001B[39m, cmap\u001B[38;5;241m=\u001B[39mcmap, norm\u001B[38;5;241m=\u001B[39mnorm,\n\u001B[0;32m   5657\u001B[0m                       interpolation\u001B[38;5;241m=\u001B[39minterpolation, origin\u001B[38;5;241m=\u001B[39morigin,\n\u001B[0;32m   5658\u001B[0m                       extent\u001B[38;5;241m=\u001B[39mextent, filternorm\u001B[38;5;241m=\u001B[39mfilternorm,\n\u001B[0;32m   5659\u001B[0m                       filterrad\u001B[38;5;241m=\u001B[39mfilterrad, resample\u001B[38;5;241m=\u001B[39mresample,\n\u001B[0;32m   5660\u001B[0m                       interpolation_stage\u001B[38;5;241m=\u001B[39minterpolation_stage,\n\u001B[0;32m   5661\u001B[0m                       \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m-> 5663\u001B[0m \u001B[43mim\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   5664\u001B[0m im\u001B[38;5;241m.\u001B[39mset_alpha(alpha)\n\u001B[0;32m   5665\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m im\u001B[38;5;241m.\u001B[39mget_clip_path() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   5666\u001B[0m     \u001B[38;5;66;03m# image does not already have clipping set, clip to axes patch\u001B[39;00m\n",
      "File \u001B[1;32mE:\\condaenvs\\pytorch\\lib\\site-packages\\matplotlib\\image.py:710\u001B[0m, in \u001B[0;36m_ImageBase.set_data\u001B[1;34m(self, A)\u001B[0m\n\u001B[0;32m    706\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_A \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_A[:, :, \u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    708\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_A\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[0;32m    709\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_A\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m3\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_A\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m4\u001B[39m]):\n\u001B[1;32m--> 710\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid shape \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m for image data\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    711\u001B[0m                     \u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_A\u001B[38;5;241m.\u001B[39mshape))\n\u001B[0;32m    713\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_A\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m3\u001B[39m:\n\u001B[0;32m    714\u001B[0m     \u001B[38;5;66;03m# If the input data has values outside the valid range (after\u001B[39;00m\n\u001B[0;32m    715\u001B[0m     \u001B[38;5;66;03m# normalisation), we issue a warning and then clip X to the bounds\u001B[39;00m\n\u001B[0;32m    716\u001B[0m     \u001B[38;5;66;03m# - otherwise casting wraps extreme values, hiding outliers and\u001B[39;00m\n\u001B[0;32m    717\u001B[0m     \u001B[38;5;66;03m# making reliable interpretation impossible.\u001B[39;00m\n\u001B[0;32m    718\u001B[0m     high \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m255\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m np\u001B[38;5;241m.\u001B[39missubdtype(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_A\u001B[38;5;241m.\u001B[39mdtype, np\u001B[38;5;241m.\u001B[39minteger) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m1\u001B[39m\n",
      "\u001B[1;31mTypeError\u001B[0m: Invalid shape (3, 32, 32) for image data"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T06:46:37.481866Z",
     "start_time": "2024-08-28T06:46:37.443731Z"
    }
   },
   "cell_type": "code",
   "source": "model=nn.Sequential(nn.Linear(3072,512),nn.Tanh(),nn.Linear(512,10),nn.Softmax(dim=1))",
   "id": "2e7181969fe0ac6a",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T10:27:42.636093Z",
     "start_time": "2024-08-28T10:27:42.622091Z"
    }
   },
   "cell_type": "code",
   "source": "imgs3,label=cifar10[99]",
   "id": "925ec51e7a212f87",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T10:27:44.637419Z",
     "start_time": "2024-08-28T10:27:44.511045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.imshow(imgs3)\n",
    "plt.show()"
   ],
   "id": "52a537d750c7b64f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T10:22:52.466323Z",
     "start_time": "2024-08-28T10:22:52.425696Z"
    }
   },
   "cell_type": "code",
   "source": "imgs,_=tensor_cifar10[99]",
   "id": "e860779d25791587",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T10:22:54.898788Z",
     "start_time": "2024-08-28T10:22:54.597883Z"
    }
   },
   "cell_type": "code",
   "source": "plt.imshow(imgs.permute(1,2,0))",
   "id": "e4fbc6a5ff632466",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x204413b5670>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T16:10:00.081443Z",
     "start_time": "2024-08-28T16:09:51.878021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "label_map={0:0,2:1}\n",
    "cifar2=[ (img,label_map[label]) for img,label in transforms_cifar10 if label in [0,2] ]"
   ],
   "id": "dbbccc1d62105be5",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T16:02:29.861135Z",
     "start_time": "2024-08-28T16:02:29.849111Z"
    }
   },
   "cell_type": "code",
   "source": "len(cifar2)",
   "id": "903418bd08abbed6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T16:10:00.097548Z",
     "start_time": "2024-08-28T16:10:00.083444Z"
    }
   },
   "cell_type": "code",
   "source": "train_model=nn.Sequential(nn.Linear(3072,512),nn.Tanh(),nn.Linear(512,2),nn.LogSoftmax(dim=1))",
   "id": "3e6fe099003c03dc",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T16:10:00.113091Z",
     "start_time": "2024-08-28T16:10:00.099459Z"
    }
   },
   "cell_type": "code",
   "source": "learning_rate = 1e-2  #超参数：学习率",
   "id": "586ede778e449d5f",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T16:10:01.474659Z",
     "start_time": "2024-08-28T16:10:01.468565Z"
    }
   },
   "cell_type": "code",
   "source": "optimizer=optim.SGD(train_model.parameters(),lr=learning_rate) #优化器",
   "id": "b47bbcaf16034672",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T16:10:03.220560Z",
     "start_time": "2024-08-28T16:10:03.207559Z"
    }
   },
   "cell_type": "code",
   "source": "loss_fn=nn.NLLLoss()",
   "id": "f4d0bb092f22c670",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T16:10:04.933566Z",
     "start_time": "2024-08-28T16:10:04.923784Z"
    }
   },
   "cell_type": "code",
   "source": "epochs=10 #不是超参数哦",
   "id": "459f9ed13ef84481",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T16:18:07.365293Z",
     "start_time": "2024-08-28T16:18:03.532630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(epochs):\n",
    "    for img, label in cifar2:\n",
    "        out=train_model(img.view(-1).unsqueeze(0))\n",
    "        print(out.shape)\n",
    "        print(out,torch.tensor([label]))\n",
    "        loss=loss_fn(out,torch.tensor([label]))\n",
    "        print(loss)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'epoch:{epoch+1},loss:{loss.item()}')"
   ],
   "id": "2108461bf1d9563b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n",
      "tensor([[-3.9873, -0.0187]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0187, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.3302, -1.2686]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.2686, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.4151, -0.0334]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0334, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.5264e+00, -5.3880e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.5962, -0.2265]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.5962, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1363, -2.0605]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1363, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.3964, -0.0341]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.3964, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.1369e-03, -6.1495e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(6.1495, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.1938, -0.0419]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0419, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.2215, -0.3492]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.3492, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.4223, -0.0929]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0929, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0640, -2.7803]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0640, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.5846, -0.0103]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0103, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.5643, -0.2347]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.2347, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.8043, -0.1798]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1798, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.7509, -0.1907]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1907, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.2626e+00, -5.1951e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(5.2626, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1522, -1.9574]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.9574, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0403, -3.2315]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0403, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.0899, -0.0062]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0062, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.5652, -0.0800]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(2.5652, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0329, -3.4299]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0329, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2885, -1.3840]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.3840, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2875, -1.3867]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.2203, -0.1149]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1149, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.6163, -0.7764]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.6163, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.5182, -0.9054]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.9054, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.1225e+00, -2.1953e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.5392, -0.0822]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(2.5392, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0493, -0.4310]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.4310, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.3959, -1.1180]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.3959, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0317, -3.4659]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0317, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.6923, -0.6940]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.6923, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.3861, -0.0125]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0125, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2742, -1.4278]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.4278, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.4967e-05, -9.6413e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(6.4967e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0251, -3.6977]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0251, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.3956e+00, -1.6704e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0193, -3.9580]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0193, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.5520e-04, -7.0646e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0219, -3.8328]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0219, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0113, -4.4852]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0113, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0070, -4.9636]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.9636, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.6306, -0.7599]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.6306, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.4831, -0.0312]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.4831, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.2330e-03, -5.2554e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(5.2554, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1791, -1.8082]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.8082, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.4200e-03, -6.0252e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.8331, -0.5704]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.5704, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.0739e-03, -6.1794e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.2296, -0.0054]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0054, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.7371, -0.6510]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.6510, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.6475, -0.7410]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.6475, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.3697, -0.2933]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.3697, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.3376, -1.2501]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.3376, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.0367e-04, -7.0095e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(7.0095, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.3956, -1.1185]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.3956, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.5497e-03, -5.6427e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0035, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.9625, -0.4812]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.9625, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1928, -1.7412]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1928, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.0996e-03, -5.7780e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0031, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.2381, -0.3424]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.3424, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.7180e+00, -1.6366e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.2096e-03, -6.7180e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.5234, -0.0836]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(2.5234, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.1762e-04, -7.7812e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2393, -1.5474]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.5474, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2577, -1.4820]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.2577, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.1914e+00, -7.5336e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0188, -3.9852]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0188, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0623, -2.8074]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.8074, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.8606e+00, -3.8569e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2484, -1.5142]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.2484, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0080, -4.8317]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0080, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1483, -1.9819]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1483, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.1323, -0.3890]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.3890, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.2888e-03, -5.4539e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0043, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.2970e-03, -6.6483e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.2289e+00, -1.9736e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.5833, -0.0785]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0785, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.7503, -0.6391]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.6391, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0229, -3.7898]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0229, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.4743, -0.9737]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.4743, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0247, -3.7129]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0247, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0338, -3.4046]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0338, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.1261e-03, -5.2760e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0051, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.1371e-04, -8.0673e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.4011e+00, -8.2609e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(8.2609e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.1601, -0.3761]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.1601, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.2254e-04, -8.4107e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.1423, -0.0160]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0160, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0724, -2.6617]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0724, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.9599e+00, -9.4965e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.6735e-03, -6.3937e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.7891e+00, -1.1266e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1683, -1.8651]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1683, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.9410, -0.0072]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0072, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.9180e+00, -3.6424e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.5341e+00, -5.3463e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0338, -3.4028]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0338, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.4754e+00, -5.6704e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0067, -5.0127]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(5.0127, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.6074, -0.2236]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.2236, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.5296e+00, -7.2715e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(7.2715e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0314, -3.4781]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.4781, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.6824, -0.7041]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.6824, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.6584e-03, -6.4027e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.5886, -0.0102]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0102, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.9212, -0.5076]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.5076, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0021e+01, -4.4464e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.4464e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0250, -3.7003]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0250, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.2352, -0.1131]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1131, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.8713e-03, -5.8544e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0029, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.9674e-04, -7.6077e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.9111e-03, -5.8407e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0029, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0280, -3.5903]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0280, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2373, -1.5546]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.2373, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.4293, -1.0525]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.4293, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.8190e+00, -4.0213e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(7.8190, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.5266e+00, -3.9873e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(5.5266, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.0353, -0.0065]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0065, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0358, -3.3473]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0358, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.5763, -0.2316]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.2316, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2203, -1.6209]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.6209, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.9368e+00, -1.3148e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.5230e-03, -5.9836e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1878, -1.7646]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1878, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.8225e-04, -8.1729e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.3504, -0.0130]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0130, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0787e-03, -6.8325e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.1505, -0.0438]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0438, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.0835e-04, -8.0845e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.2632e-03, -6.0921e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.8697e+00, -3.8223e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.5482e-04, -7.9441e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.6139e-04, -7.3215e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.7637e+00, -4.2501e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.3235, -0.3095]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.3235, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0301, -3.5197]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.5197, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.5419, -0.8714]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.5419, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.9462, -0.1541]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1541, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0072, -4.9424]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0072, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.8350, -0.0080]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(4.8350, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.1762e-03, -5.7537e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0032, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.6574, -0.0095]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0095, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.7401, -0.0240]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0240, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.3622e-03, -6.0493e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.8926e-04, -7.0256e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.7186e-04, -7.8971e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.5201e-03, -6.4898e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.0924e+00, -2.2625e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.0960e+00, -8.2876e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.0265e+00, -3.2670e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.0554e-03, -5.5097e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0041, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.1786, -0.0154]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(4.1786, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.4073, -0.0944]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0944, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.5595e+00, -3.8581e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0039, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.1961, -0.3601]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.3601, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0217, -3.8398]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0217, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.3108, -0.0372]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0372, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0633e+01, -2.4080e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.4080e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.3437, -1.2350]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.2350, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0950, -2.4010]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.4010, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.7668, -0.0649]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0649, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.7819, -0.6117]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.6117, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0375, -3.3032]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0375, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.9658e+00, -3.4720e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.8261e+00, -1.4686e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(8.8261, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.4903e+00, -4.1350e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0041, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.4838, -0.0312]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0312, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.0322, -0.0179]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0179, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.5209, -0.2466]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.2466, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.8502, -0.0079]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(4.8502, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.2233, -0.0406]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0406, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.3469e+00, -1.7537e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0728, -2.6565]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0728, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1745, -1.8320]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1745, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0480, -3.0603]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0480, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0384, -3.2796]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.2796, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.1594, -0.0058]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0058, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2388, -1.5492]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.2388, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0123, -4.4082]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0123, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.5230e-04, -7.7014e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.3166e+00, -6.6461e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0963, -2.3885]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.3885, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0208, -3.8853]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0208, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.6503, -0.0732]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0732, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.6840e+00, -4.6016e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1683, -1.8649]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1683, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.1262, -0.0060]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0060, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1531, -1.9525]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1531, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.0505e-04, -7.1251e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.8882, -0.5300]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.5300, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.6097, -0.2231]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.2231, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.5284e-03, -6.4843e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0369, -3.3184]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0369, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.1735, -0.1208]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1208, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0063, -5.0647]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0063, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.9838, -0.0188]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0188, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1273, -2.1245]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1273, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.5224e+00, -4.0044e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0040, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.1344, -0.1259]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1259, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.1406, -0.3851]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.3851, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0103, -4.5844]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.5844, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0172, -4.0732]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0172, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.6042, -0.0768]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0768, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.5959e-03, -6.4411e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1510, -1.9653]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.9653, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.5601e-04, -7.9407e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.5918, -0.0778]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0778, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1096, -2.2655]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.2655, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.9974, -0.4602]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.4602, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0568e+01, -2.5749e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.5749e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.3756, -0.2913]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.2913, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.7041, -0.0249]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.7041, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2087, -1.6693]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.2087, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.9347, -0.0072]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0072, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.4198, -1.0705]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.0705, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.1337e+00, -2.9357e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.8120e-05, -1.0915e+01]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.8120e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.1398e+01, -1.1206e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.1206e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.5166, -0.0842]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(2.5166, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.3833e+00, -1.6910e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.1325e-05, -1.1393e+01]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.1325e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.1463e-03, -6.7719e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(6.7719, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.5639, -0.0105]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(4.5639, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2554, -1.4898]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.2554, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.8686, -0.5439]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.5439, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.9880e-03, -5.8146e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0030, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.9301, -0.0198]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0198, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0212, -3.8640]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0212, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.9185e-03, -6.2572e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0064, -5.0577]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0064, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0109, -4.5270]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.5270, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.5197e+00, -4.0151e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0040, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.1364, -0.3871]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.1364, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.4976, -0.9365]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.4976, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.9616, -0.4817]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.9616, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.1012e+00, -8.2447e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.1059e-05, -9.4209e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(8.1059e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0717, -2.6708]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0717, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.1068e+00, -3.0155e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.3853, -1.1403]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.1403, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.3344e-03, -6.6200e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.5560e-04, -7.4957e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.9351e-05, -9.9164e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(4.9351e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0448, -3.1272]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.1272, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.3934, -0.0958]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(2.3934, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0862, -2.4935]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0862, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2488, -1.5129]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.2488, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0808, -2.5560]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0808, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.5821, -0.0103]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0103, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0393, -3.2554]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0393, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.4408, -0.0326]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.4408, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.5894, -0.0780]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0780, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.4560, -0.0897]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(2.4560, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1085, -2.2748]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1085, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.1909e+00, -1.0192e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1075, -2.2832]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.2832, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.5050, -0.0852]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0852, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.3545e+00, -2.3541e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.9558, -0.0534]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0534, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0284, -3.5748]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0284, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.7546e-04, -8.6480e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.0422e+00, -1.1837e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.1753e-04, -9.0489e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.2978, -0.3190]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.3190, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.3805e-04, -7.0849e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.0968, -0.0462]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0462, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.3603e-05, -1.0655e+01]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(2.3603e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.4562e-03, -6.5326e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.4457, -1.0227]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.4457, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.9152, -0.0201]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0201, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.0791e+00, -2.2927e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.4701, -0.2612]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.2612, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.5726e-03, -5.9641e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0285, -3.5708]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0285, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0165, -4.1097]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0165, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.3524e-04, -6.9752e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.7582e+00, -3.1618e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0032, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.5610, -0.0804]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0804, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.6056e-04, -7.0584e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0280, -3.5889]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0280, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.8490, -0.0596]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0596, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.4812, -0.2580]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.4812, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.8610e-06, -1.2755e+01]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(2.8610e-06, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0356, -3.3519]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.3519, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.2481, -0.0144]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0144, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.4870, -0.0113]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0113, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.3869e+00, -1.6848e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2405, -1.5427]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.2405, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.5968, -0.7998]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.7998, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.8623e-05, -1.0161e+01]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.8623e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.8823e-03, -6.2762e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0245, -3.7226]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0245, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.6929, -0.0252]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.6929, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.8159, -0.1776]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1776, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.5055e-03, -5.4047e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0045, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.7957e+00, -5.5669e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(5.5669e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.6366e-04, -8.7176e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.3813e-05, -9.2746e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(9.2746, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1944, -1.7334]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1944, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.3966, -0.0124]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0124, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.1682, -0.0156]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0156, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.5096, -0.0304]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0304, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0062e-03, -6.9021e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0182, -4.0151]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0182, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0917, -0.4089]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.0917, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0587e+01, -2.5272e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.5272e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0096, -4.6542]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0096, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.0761e-04, -7.8055e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(7.8055, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.2454, -0.3394]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.3394, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.3195e-03, -5.7096e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(5.7096, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0105, -4.5610]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.5610, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0563, -0.4273]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.0563, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.4024, -0.0949]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0949, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.2422, -0.0053]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(5.2422, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.8025, -0.0226]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0226, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.3285, -1.2729]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.2729, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.4639, -0.2631]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.4639, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0266, -3.6399]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0266, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1358, -2.0634]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1358, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0351, -3.3675]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0351, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0135, -4.3146]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0135, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.5150e+00, -1.4822e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.7854e-04, -7.8794e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.1834e+00, -2.0656e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.5369e+00, -7.2119e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(7.2119e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0124, -4.3966]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.3966, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.7048, -0.2007]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.7048, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.3684e-03, -6.5948e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.8929e-03, -6.2706e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.2218e+00, -9.8820e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(9.8820e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.5207e-03, -6.4894e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0069, -4.9841]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0069, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.0328, -0.0065]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0065, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0058, -5.1585]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0058, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0146, -4.2331]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.2331, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.6583, -0.0726]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0726, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1452, -2.0012]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.0012, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1605, -1.9084]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1605, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.6171, -0.2212]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.2212, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1224, -2.1607]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1224, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1293, -2.1094]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.1094, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.3479, -1.2247]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.3479, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0521, -2.9806]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0521, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.3124, -1.3156]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.3124, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.0546, -0.0483]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.0546, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0199, -3.9283]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.9283, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.6547, -0.0262]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.6547, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.6179, -0.0099]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0099, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.4915, -0.2550]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.2550, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.1437e+00, -2.1493e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.4803, -0.0114]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(4.4803, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.6546, -0.0262]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0262, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.9419, -0.0542]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(2.9419, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0492, -3.0367]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0492, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0785, -2.5843]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.5843, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.5188, -0.0840]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0840, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0480, -3.0604]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.0604, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.2010, -0.0416]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0416, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1281, -2.1184]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.1184, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.2512, -0.0143]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0143, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.9114, -0.0074]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0074, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.5051e+00, -4.0741e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0041, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.5842, -0.0785]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0785, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.4122, -0.2792]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.4122, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.1607e+00, -1.0514e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0844, -2.5139]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0844, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.6437e-03, -6.4116e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(6.4116, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.8428, -0.5630]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.8428, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.5614, -0.2355]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.2355, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1139, -2.2291]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1139, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.0649e+00, -3.1442e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.6306e+00, -4.8554e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0961, -2.3899]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.3899, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.6389e+00, -1.3094e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.2161, -0.1154]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1154, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.6108, -0.0100]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0100, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.7280, -0.6595]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.7280, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2896, -1.3806]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.2896, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.8954, -0.1628]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.8954, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.6488, -0.0734]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0734, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.9871, -0.0187]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0187, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.9098, -0.0202]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.9098, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.5791, -0.8220]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.5791, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.1063, -0.1297]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(2.1063, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.0887, -0.0466]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0466, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0430e+01, -2.9563e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.9563e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0259, -3.6676]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0259, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.4341e+00, -1.6072e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.0026, -0.0184]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0184, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.9959, -0.0513]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(2.9959, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0846, -2.5114]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.5114, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.0320e-04, -7.0101e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0418e+01, -2.9921e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(10.4184, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0106, -4.5537]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0106, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.9638, -0.0070]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0070, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.6657, -0.0721]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(2.6657, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.3829, -0.0345]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.3829, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.5868, -0.2289]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.2289, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0320, -3.4569]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0320, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0871, -2.4843]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.4843, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.4824, -0.9606]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.9606, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.2084e-03, -6.7190e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.2929e+00, -6.8057e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2275, -1.5921]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.2275, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.7742, -0.0085]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0085, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.7649, -0.1878]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.7649, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0563, -2.9055]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0563, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1673, -1.8704]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1673, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.3944e-03, -6.5760e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.9895, -0.1471]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1471, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.0235e-03, -5.8029e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0030, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.4643e-03, -5.6670e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0035, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.5406, -0.2411]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.2411, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.3898e+00, -2.2719e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.4104, -0.0941]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(2.4104, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0053, -5.2414]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0053, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.6318e-04, -7.3188e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(7.3188, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.8183, -0.5819]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.8183, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2392, -1.5479]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.5479, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.1316e-03, -6.1519e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(6.1519, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.9510, -0.0537]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0537, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.9366, -0.1557]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1557, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.3797e+00, -4.6198e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0046, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.7888, -0.0084]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0084, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.2699, -0.0141]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0141, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.1922, -0.0152]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0152, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.0470, -0.0487]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.0470, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.7186, -0.1976]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1976, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.5353e+00, -1.4523e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.2854e+00, -1.8650e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.3477, -0.3009]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.3009, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.9024e+00, -2.7368e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.9212, -0.0554]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0554, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1050, -2.3061]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1050, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2687, -1.4455]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.2687, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0424, -3.1828]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0424, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.5546e+00, -1.4245e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1869, -1.7692]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1869, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1122, -2.2431]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1122, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.7229, -0.1967]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1967, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2283, -1.5892]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.2283, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.0638e+00, -8.5591e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0759, -2.6165]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.6165, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0416, -3.1995]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.1995, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.5735, -0.2323]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.2323, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.6721, -0.7146]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.6721, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0939, -2.4121]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.4121, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.2901e+00, -1.8564e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.9546, -0.0071]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0071, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.7293, -0.0675]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(2.7293, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.5738, -0.0284]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0284, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0131, -4.3396]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.3396, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.8094, -0.5890]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.8094, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.5715e-03, -5.9645e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.6558, -0.7320]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.6558, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.1753e+00, -2.0824e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(6.1753, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.7646, -0.0651]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0651, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.6026, -0.7928]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.6026, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.7320, -0.0242]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.7320, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.7454, -0.6435]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.6435, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0212, -0.4465]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.4465, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.5798, -0.8210]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.8210, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.1694, -0.3718]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.1694, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0064, -5.0613]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0064, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.1764e+00, -1.0347e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0118, -4.4495]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0118, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0062, -5.0835]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0062, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.9170e+00, -9.9121e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1783, -1.8121]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1783, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0262, -3.6549]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.6549, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.6844e+00, -1.6926e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.2874e-04, -8.9575e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.9264, -0.5041]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.5041, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.1055e-03, -5.4975e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0041, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.9293, -0.0549]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(2.9293, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.7815, -0.1844]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1844, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.1147, -0.3975]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.3975, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.8431, -0.0217]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0217, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.9663, -0.4788]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.4788, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.3659, -0.0128]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(4.3659, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.7514e+00, -4.3025e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.4171e-03, -6.0264e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.4295e-03, -5.6770e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0034, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0062, -5.0798]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(5.0798, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.8493e+00, -1.0608e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(6.8493, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.6258, -0.2191]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.6258, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0367, -3.3245]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0367, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.6180e-03, -5.6236e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0036, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2046, -1.6874]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.2046, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0106, -4.5550]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0106, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.8275, -0.5747]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.8275, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.4439e+00, -2.1527e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0135, -4.3144]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0135, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.3248, -1.2825]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.3248, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0991e-03, -6.8138e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.7377e-05, -9.3455e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(8.7377e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.9802e-05, -1.0419e+01]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(2.9802e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.1263e+01, -1.2875e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.2875e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.3372, -0.0132]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0132, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.5305e-04, -8.2819e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.5520, -0.8576]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.8576, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.8284e-04, -7.2896e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.8367, -0.5676]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.5676, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0426, -3.1775]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0426, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.7999e+00, -1.1145e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.4135, -1.0827]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.4135, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.1196, -0.0164]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0164, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.9698e-03, -6.2308e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1019, -2.3347]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1019, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1489, -1.9782]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.9782, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0407e+01, -3.0159e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.0159e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.9417, -0.0542]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0542, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.9557, -0.0193]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0193, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.9299, -0.0073]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0073, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.3188e+00, -2.4387e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.9868e+00, -1.2504e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.3767, -0.0975]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0975, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0139, -4.2860]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.2860, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.7406, -0.0240]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0240, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.7512, -0.6383]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.6383, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.2405, -0.0145]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0145, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0201, -3.9161]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0201, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.0918e+00, -8.3233e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.3898, -1.1308]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.3898, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.0774e+00, -8.4436e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.2982, -0.0376]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0376, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.4931e-04, -7.1967e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.7691, -0.6226]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.6226, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.1896e-04, -8.4267e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.1235e-03, -6.7919e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.2918e-03, -6.6524e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(6.6524, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.4821, -0.0873]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(2.4821, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.2388, -0.1127]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1127, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.2925e-03, -6.6519e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0680, -2.7221]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0680, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0206, -3.8924]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.8924, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0494, -3.0327]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0494, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0252, -3.6947]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0252, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0829, -2.5316]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0829, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2308, -1.5793]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.2308, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.7307, -0.0089]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(4.7307, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0378, -3.2955]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0378, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.4469, -1.0206]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.0206, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0138, -4.2873]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0138, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.2289e-03, -6.7022e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(6.7022, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.5882, -0.8104]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.5882, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0182, -4.0162]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0182, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.3019, -0.1054]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1054, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2558, -1.4884]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.4884, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.9030e+00, -2.7351e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.4712, -0.0115]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0115, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.1089, -0.4004]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.1089, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.1353e+01, -1.1682e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.1682e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2681, -1.4474]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.2681, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0125, -4.3861]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0125, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.0548, -0.1371]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1371, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2035, -1.6922]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.2035, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.6590e+00, -4.7184e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.5349, -0.8812]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.8812, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1033, -2.3213]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.3213, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0531, -2.9615]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.9615, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0173, -4.0652]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.0652, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.4673, -0.9853]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.9853, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.9596e+00, -1.2850e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.4663, -0.9870]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.9870, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.1501e+00, -7.8504e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(7.1501, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0228, -3.7922]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0228, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.5680, -0.8363]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.8363, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.5091, -0.0304]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0304, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.1071e+01, -1.5497e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.5497e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.7318e+00, -1.1932e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.1431e-03, -5.7641e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0031, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.3707e-04, -7.9953e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.7531e+00, -5.8172e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(5.8172e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.1663e+00, -2.1011e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.4207e-04, -7.9805e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.6688, -0.7181]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.7181, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.4408e-04, -7.7198e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(7.7198, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.3255, -0.1028]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1028, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.6206, -0.7714]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.6206, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.7310e+00, -5.9364e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(5.9364e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.9027, -0.5200]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.9027, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.0246e-03, -5.5173e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0040, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.0191, -0.0066]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0066, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.2027e-04, -9.0260e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0184, -4.0021]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0184, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0185, -3.9982]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.9982, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.1750, -0.0155]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0155, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.0569, -0.0482]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0482, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0480, -3.0599]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.0599, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.2268, -0.0054]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0054, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0170, -4.0835]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.0835, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.8859, -0.0574]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(2.8859, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.6368, -0.2164]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.6368, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0907, -2.4451]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.4451, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.4056, -1.0983]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.4056, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.2411e-05, -1.0705e+01]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(10.7053, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.3352e+00, -4.8307e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0048, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.0252, -0.0066]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0066, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0111, -4.5045]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0111, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.3889, -0.0962]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0962, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.9362e+00, -9.7251e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.5454, -0.0107]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(4.5454, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0615, -2.8186]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.8186, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.3972, -0.0954]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(2.3972, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.4760, -0.0314]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.4760, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.3280, -0.0365]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0365, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.3715, -0.0127]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(4.3715, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0951, -2.4002]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0951, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.4869, -0.9532]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.4869, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1015, -2.3378]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.3378, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.9108, -0.1601]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.9108, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0462, -3.0970]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.0970, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.5450e+00, -1.9453e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0767e+01, -2.1100e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.1100e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.5656, -0.0800]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0800, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0058, -5.1446]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(5.1446, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0212, -3.8645]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0212, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0574, -0.4267]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.0574, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.9243e+00, -2.6772e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0257e+01, -3.5166e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.5166e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.4056, -1.0984]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.4056, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.5271e+00, -1.4644e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.3590, -0.0354]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.3590, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.5142e-03, -5.9871e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.5195e-03, -6.4901e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0970, -2.3809]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0970, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0423, -3.1842]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0423, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0125, -4.3893]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0125, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0289, -3.5595]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.5595, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0153, -4.1846]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0153, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.3936, -0.0342]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0342, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.5566, -0.2368]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.5566, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.5601e-04, -7.9408e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.5172e-03, -5.9859e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(5.9859, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0188, -3.9810]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0188, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.9551e-04, -7.4263e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0184, -4.0069]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0184, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.6334, -0.0098]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0098, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.8713e+00, -1.4042e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0836, -2.5232]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.5232, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.6580, -0.0095]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(4.6580, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.2954e+00, -5.0270e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(5.2954, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.5444, -0.8679]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.5444, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.4529e+00, -5.7990e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.1185e+01, -1.3828e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.3828e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.6699, -0.2086]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.6699, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.2519e+01, -3.6955e-06]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.6955e-06, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0256, -3.6782]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0256, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.0620, -0.0064]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0064, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.6862e+00, -1.6891e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1145, -2.2242]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.2242, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.8978, -0.5234]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.8978, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.5716, -0.8315]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.5716, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.6373, -0.0742]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0742, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.4719, -0.0882]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0882, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0280, -3.5893]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0280, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.0157e-03, -6.2078e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.8562, -0.1699]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.8562, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.7887e+00, -1.5246e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.7615, -0.0653]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0653, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.4765e+00, -7.6649e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(7.6649e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.3863e-04, -8.3409e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0126e+01, -4.0054e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.0054e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.7271e-04, -8.2073e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(8.2073, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.7297e-03, -5.5933e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(5.5933, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0176, -4.0502]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0176, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.8291, -0.5735]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.5735, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.5832, -0.8167]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.5832, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.3338, -0.0132]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0132, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0600, -2.8437]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.8437, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.0746, -0.0473]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.0746, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.5338, -0.8827]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.5338, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0401e+01, -3.0398e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.0398e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0493e+01, -2.7775e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.7775e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.5039, -0.9267]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.9267, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0512, -2.9981]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0512, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.6906, -0.0702]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0702, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.4367, -0.2714]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.4367, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.8540, -0.5546]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.5546, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.2904, -0.3218]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.3218, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1302, -2.1033]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1302, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.9854, -0.0188]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0188, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0274, -3.6093]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0274, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1861, -1.7732]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1861, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.2975, -0.1059]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(2.2975, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2303, -1.5814]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.2303, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.1192e-03, -6.7957e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.2184, -0.1152]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1152, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0889, -2.4646]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.4646, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.2660e-03, -6.6725e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.1542e-03, -6.7649e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.9365e+00, -2.6447e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.9711, -0.4759]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.9711, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.7510e-03, -6.3484e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0247, -3.7143]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0247, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1195, -2.1836]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.1836, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0956, -2.3953]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.3953, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0522, -2.9794]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0522, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0441, -3.1430]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0441, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.2602, -0.0391]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0391, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0422e+01, -2.9802e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.9802e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.3142, -1.3108]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.3108, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.1214e+00, -2.9714e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.0001, -0.1454]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1454, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0948e+01, -1.7643e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.7643e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0123, -4.4049]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.4049, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.1944e-04, -9.0331e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(9.0331, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.4146, -1.0805]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.4146, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.3757, -0.0976]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0976, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1401, -2.0348]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1401, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0110, -4.5196]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0110, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.5939e+00, -5.0365e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0186, -0.4480]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.4480, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1279, -2.1201]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.1201, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.9520, -0.0194]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0194, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0395, -3.2506]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0395, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0171e+01, -3.8265e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.8265e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.5116, -0.0303]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0303, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0467, -3.0880]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0467, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.9194e+00, -2.6903e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.8187, -0.5816]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.5816, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0813e+01, -2.0146e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.0146e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.9981, -0.4598]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.4598, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.9711e+00, -9.3905e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.4758, -0.9712]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.9712, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.3077, -0.0373]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.3077, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.6935e+00, -4.5587e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.2071, -0.0055]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0055, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.4339e+00, -1.6076e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0152, -4.1909]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0152, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.8825, -0.0208]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.8825, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0350, -3.3712]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0350, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.9024, -0.0565]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0565, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.7209, -0.6661]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.7209, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.7430e+00, -1.1797e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0427, -3.1756]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0427, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0089, -4.7272]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0089, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.4088, -0.0336]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.4088, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.4748e+00, -7.6768e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(7.6768e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.8582e-04, -8.1604e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.1474e-03, -6.7708e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(6.7708, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.2413, -0.0399]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.2413, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.4259, -0.2748]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.2748, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1246, -2.1446]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1246, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.5704, -0.0285]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0285, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1296, -2.1074]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1296, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0069, -4.9760]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.9760, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.9638, -0.0070]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0070, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.4727e+00, -5.6859e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.8345, -0.1740]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.8345, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0848e+01, -1.9431e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.9431e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.8273, -0.1754]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.8273, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.1364e+00, -2.9274e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.1835e+01, -7.2717e-06]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(7.2717e-06, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1187, -2.1897]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1187, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.7843e-03, -6.3297e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(6.3297, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.2978, -0.0137]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0137, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.6372, -0.2163]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.6372, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.6703, -0.7165]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.7165, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0093, -4.6809]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0093, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0201, -3.9186]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.9186, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.3568, -0.2977]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.2977, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1188, -2.1892]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1188, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.4834e-03, -5.9994e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.6008, -0.2253]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.6008, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0233, -3.7716]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.7716, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0192, -3.9611]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0192, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0210, -3.8732]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0210, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.3321, -1.2637]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.3321, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.5205e-03, -6.4894e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.8804e-04, -7.6254e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.5187e+00, -5.4297e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.8997e+00, -1.3649e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.2828, -0.3247]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.3247, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.3792e+00, -4.6223e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0046, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0945, -0.4075]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.0945, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.9360, -0.0197]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0197, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.1796, -0.0425]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0425, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.4436, -0.2693]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.2693, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0124, -4.3930]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0124, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0633, -2.7906]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0633, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.3278, -1.2747]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.3278, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0064, -5.0483]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(5.0483, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.6944, -0.0252]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0252, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.6407, -0.7484]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.7484, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.4270, -0.0924]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(2.4270, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.3602e+00, -6.3626e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.6364e-03, -6.4161e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.5305, -0.0830]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0830, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0719e+01, -2.2053e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(10.7194, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.0176, -0.1427]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(2.0176, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.0656, -0.0477]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0477, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0100, -4.6103]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0100, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.4357, -1.0408]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.4357, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.1050e-03, -6.1645e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.9939, -0.0068]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0068, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.2119e+00, -2.0074e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(6.2119, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2036, -1.6918]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.2036, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.7167, -0.0684]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(2.7167, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0257, -3.6753]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0257, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0958, -2.3934]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0958, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0151, -4.1988]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0151, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.6173, -0.0099]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0099, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.1063, -0.1298]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(2.1063, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.4984, -0.0112]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0112, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.5864e+00, -5.0746e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(7.5864, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.2303, -0.0054]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0054, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.2813, -0.3253]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.2813, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0168, -4.0971]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0168, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1734, -1.8376]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1734, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.6322, -0.0098]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0098, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1584, -1.9210]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1584, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.4604e+00, -4.2609e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0043, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.2900, -0.3220]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.3220, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.8487e+00, -3.9033e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.1654, -0.3737]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.3737, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.6699e-04, -8.2285e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1433, -2.0133]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.0133, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0539, -2.9472]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0539, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0207, -3.8893]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0207, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0930, -0.4083]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.4083, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.7663e+00, -4.2382e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0174, -4.0598]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0174, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.1678e-04, -6.9951e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.8123e+00, -4.0487e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.7629e-04, -8.6437e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(8.6437, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0284, -3.5755]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0284, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.2324, -0.1135]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(2.2324, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.7707, -0.1866]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1866, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1111, -2.2523]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1111, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1005, -2.3472]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1005, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.3203e+00, -6.6223e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(7.3203, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.9744, -0.0524]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0524, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.5179e+00, -5.4345e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.9478, -0.1538]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1538, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0444, -3.1360]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0444, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.0024e-03, -5.5229e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0040, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.4885, -0.0113]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0113, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0437, -3.1522]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.1522, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0167, -4.0989]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.0989, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.3021, -1.3442]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.3442, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0286, -3.5683]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.5683, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.3541, -1.2100]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.3541, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.2731e+01, -2.9802e-06]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.9802e-06, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.6056e-04, -7.3228e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0588, -2.8629]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0588, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.7615e-03, -5.8934e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0028, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0161, -4.1376]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0161, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.8973e+00, -1.0111e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.3887, -0.2869]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.3887, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1154, -2.2167]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.2167, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.5154, -0.0110]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0110, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.2342e+01, -4.4107e-06]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.4107e-06, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.1471e-05, -1.0367e+01]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.1471e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.7483e-05, -9.4653e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(9.4653, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.0119e+00, -2.4523e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0191, -3.9669]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0191, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.6763e+00, -4.6385e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.3267, -0.0133]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0133, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1147, -2.2219]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1147, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.7417, -0.6469]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.6469, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0185, -3.9991]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.9991, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2998, -1.3507]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.2998, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.9417, -0.4942]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.4942, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0161, -4.1362]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0161, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.0527, -0.0484]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.0527, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2592, -1.4769]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.4769, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.0419, -0.0065]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(5.0419, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0124, -4.3949]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.3949, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1668, -1.8735]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1668, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2716, -1.4361]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.2716, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.3984, -1.1130]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.3984, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.9766, -0.4726]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.9766, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.1955e-04, -8.0486e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.5823, -0.0282]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.5823, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.7373, -0.0669]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0669, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0217, -3.8404]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0217, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.3802, -0.0346]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0346, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.8190e-03, -6.3103e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2766, -1.4202]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.2766, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.0583, -0.0064]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(5.0583, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0955, -2.3957]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0955, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.0266e-06, -1.3126e+01]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(2.0266e-06, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.6652e+00, -4.6898e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.5720e-05, -9.2547e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(9.5720e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.0608e-04, -8.0917e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(8.0917, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0699, -2.6953]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0699, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0344e+01, -3.2186e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.2186e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.4493, -0.0118]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0118, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.4828e-04, -8.3012e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.4139e+00, -2.2182e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0470, -3.0818]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.0818, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2491, -1.5120]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.2491, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.0667, -0.0063]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0063, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.9681, -0.1505]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1505, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.5366, -0.0824]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0824, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.9050, -0.1611]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.9050, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.8885, -0.5298]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.5298, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0778, -2.5917]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0778, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.0715, -0.0475]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.0715, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0793, -0.4152]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.4152, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2663, -1.4532]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.2663, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.9898, -0.0516]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0516, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.3125, -1.3152]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.3152, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.0196, -0.1424]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1424, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0080, -4.8322]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.8322, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.9222e+00, -2.6829e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.7722, -0.0233]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.7722, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0377, -3.2961]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0377, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0192, -3.9608]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.9608, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.0414e+00, -3.2193e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(8.0414, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2855, -1.3929]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.2855, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.3247, -0.0133]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0133, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.5478e-03, -6.4717e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.5750e+00, -5.1330e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.4925, -0.0863]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0863, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.5463, -0.8653]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.5463, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0494, -3.0327]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0494, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.3651, -0.0128]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(4.3651, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.5535, -0.0810]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0810, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.3379e-06, -1.2597e+01]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.3379e-06, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.3450, -0.0359]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0359, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.4306e+01, -5.9605e-07]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(5.9605e-07, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0061, -5.1096]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0061, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0859e-04, -9.1284e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.7920e+00, -1.5198e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.8669, -0.1679]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1679, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.7418e-06, -1.2828e+01]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(2.7418e-06, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.6680, -0.0094]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(4.6680, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.8985e-03, -5.5491e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0039, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.9012e+00, -1.0072e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0682, -2.7185]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0682, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2150, -1.6428]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.2150, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.2226e-03, -6.1102e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.0356e-04, -7.2597e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.5101e-04, -7.9549e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.5029e-03, -6.5011e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0315, -3.4722]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0315, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.1382e+00, -7.9445e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.7901, -0.0083]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0083, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0715, -2.6729]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0715, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.8098e-04, -7.4510e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0070, -4.9648]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.9648, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0129, -4.3560]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0129, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.1810, -0.0424]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.1810, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.1841e+00, -7.5884e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.1372e+01, -1.1563e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.1563e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.1036, -0.0459]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0459, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.4644e-03, -6.0071e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.6289e+00, -1.7892e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.7185e-03, -5.5963e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0037, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.5320e+00, -1.4572e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.1509e-04, -7.5715e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(7.5715, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.3007, -1.3481]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.3007, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.6690e+00, -1.2706e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.0723e+00, -3.1216e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(8.0723, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.4580, -1.0011]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.4580, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.1721, -0.3706]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.1721, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.0693, -0.0063]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0063, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.4428, -0.0325]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.4428, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0173, -4.0681]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.0681, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0359, -3.3457]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.3457, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.8491, -0.1712]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.8491, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.1958e-04, -7.3868e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.2834e+00, -6.8701e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.9120, -0.0074]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0074, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0205, -3.8985]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0205, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.7573e+00, -3.1648e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0032, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.7281, -0.6593]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.7281, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.3571e-04, -6.9747e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.5192e-05, -9.8037e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(5.5192e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0336, -3.4090]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.4090, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.1069e+00, -8.1982e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.8616, -0.0078]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0078, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0100, -4.6081]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0100, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.9633, -0.1513]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1513, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.2339, -0.3441]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.3441, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0299, -3.5240]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0299, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0426, -3.1777]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0426, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.3871e+00, -4.5856e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0046, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.2662, -0.1095]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(2.2662, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0235, -3.7642]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.7642, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.9677e+00, -9.4226e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0072, -4.9338]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0072, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2431, -1.5335]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.2431, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.8037e-03, -6.3188e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2473, -1.5183]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.5183, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.9136e+00, -2.7061e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0380, -3.2899]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0380, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.3371e+00, -8.8092e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(8.8092e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0818, -2.5440]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0818, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.2570e+00, -2.5948e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.3130, -0.3134]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.3134, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.4905, -0.2552]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.2552, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.4756e-03, -6.5195e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0843, -2.5152]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0843, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1176, -2.1988]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1176, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0103, -4.5848]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0103, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0448, -3.1271]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0448, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0570, -2.8938]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.8938, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.3091e+00, -2.4626e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.4589, -0.0320]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0320, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.1064e+00, -2.2310e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.3985, -1.1128]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.1128, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.2723, -0.3288]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.2723, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.0122, -0.0067]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(5.0122, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0060, -5.1169]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0060, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0546, -2.9346]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0546, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2493, -1.5112]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.2493, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1499, -1.9721]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.9721, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.5434, -0.0819]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0819, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.4073e-03, -6.0305e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.4823e+00, -5.6311e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(7.4823, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0428, -3.1724]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0428, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0433, -3.1619]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0433, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.3576, -0.2974]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.3576, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0257, -3.6734]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0257, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.4691e+01, -3.5763e-07]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.5763e-07, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.2909, -0.3216]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.3216, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.2544, -0.3358]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.2544, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0572, -2.8898]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0572, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.4550e+00, -4.2841e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0043, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.1580e-03, -6.7616e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.9902, -0.1470]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1470, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0471, -3.0781]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0471, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.8552, -0.5537]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.5537, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0909e+01, -1.8358e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.8358e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.8580e-03, -5.8591e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0029, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.1784e-03, -5.7530e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0032, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.8774e-04, -8.5807e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.8198e-05, -9.4560e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(7.8198e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.7821e+00, -3.0868e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0031, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.4291, -0.0120]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(4.4291, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.6757e-06, -1.1916e+01]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(6.6757e-06, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.2148e+00, -2.0017e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.4039e-05, -9.3841e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(8.4039e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0026e-03, -6.9057e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.3743, -0.0977]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(2.3743, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.8109, -0.1785]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1785, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.1815e-05, -1.0734e+01]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(2.1815e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.2727e+01, -2.9802e-06]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.9802e-06, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.9232e-05, -9.9198e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(4.9232e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.4376e+01, -5.9605e-07]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(5.9605e-07, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.9767e+00, -4.6491e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.6491e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.2589e+00, -1.9153e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.4516e-05, -9.3784e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(8.4516e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.8747, -0.0077]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0077, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.9111e-03, -6.2610e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(6.2610, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2317, -1.5759]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.5759, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.6779e+00, -3.4265e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0034, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2007, -1.7047]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.2007, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.4926, -0.9443]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.4926, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.1672e+01, -8.5830e-06]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(8.5830e-06, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.2291e+01, -4.6492e-06]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.6492e-06, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.6041, -0.0101]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(4.6041, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.6575e+00, -6.3894e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(6.3894e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0067e+01, -4.2438e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.2438e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0396e+01, -3.0517e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(10.3958, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.0589, -0.0064]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0064, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0214, -3.8554]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0214, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.1431e+01, -1.0848e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.0848e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0335, -3.4128]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0335, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1698, -1.8566]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.8566, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0696, -2.6996]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.6996, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.1635e+00, -7.7468e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.8198, -0.5807]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.5807, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0264, -3.6463]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.6463, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0109, -4.5201]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0109, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.7207, -0.0089]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0089, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0715, -2.6741]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0715, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.1306e+00, -8.0053e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0822, -2.5396]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.5396, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.5772e+00, -1.3927e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.1653, -0.1218]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1218, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.4282e+00, -1.6166e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0995, -2.3566]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.3566, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.8633, -0.1686]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.8633, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.5222e-04, -8.2852e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.9073e-05, -1.0864e+01]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.9073e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.7310e-03, -5.9044e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.4066e-03, -6.5673e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.4886e-05, -9.2626e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(9.4886e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.5166, -0.2478]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.2478, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.9282e+00, -3.6054e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0132, -4.3311]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0132, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0100, -4.6151]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.6151, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0341, -3.3968]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0341, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.4247, -1.0612]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.4247, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.7069e-04, -8.2145e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.9214, -0.1583]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1583, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0457, -3.1087]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0457, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.9458, -0.0071]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0071, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.3183, -0.0369]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0369, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.2467e-04, -8.0327e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.2274, -0.3468]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.2274, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.4057e-03, -6.0311e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(6.0311, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.2267, -0.1142]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1142, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0269, -3.6294]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0269, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.4927, -0.0113]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0113, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0117, -4.4543]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.4543, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0130, -4.3497]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0130, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.3120, -1.3167]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.3120, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.4429, -0.2695]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.4429, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0165, -4.1117]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0165, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0100, -4.6073]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.6073, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.1097, -0.1293]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(2.1097, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0076, -4.8871]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0076, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.4144e-03, -6.5618e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.6153e+00, -3.6485e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0036, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0556, -2.9179]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0556, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.3390, -1.2465]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.3390, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.4370e-03, -6.0182e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.3685e-03, -6.5947e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.8006, -0.0083]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(4.8006, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.0897e+00, -2.2686e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0397, -3.2462]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0397, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0302, -3.5163]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0302, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0106, -4.5479]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.5479, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.5877e-03, -6.4463e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.6198e-03, -6.4263e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0194, -3.9503]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.9503, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0054, -5.2333]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0054, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.4917e-04, -7.5073e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(7.5073, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.4551, -0.0321]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0321, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.2053, -0.1168]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1168, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0142, -0.4505]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.0142, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.0619, -0.0479]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0479, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.2679, -0.3305]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.3305, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.7736e-03, -5.3470e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0048, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.5834e-04, -7.4909e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.7356, -0.6524]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.6524, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.6517, -0.7364]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.7364, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.2152e+00, -7.3561e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.6381e+00, -6.5205e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(6.5205e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0084, -4.7790]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0084, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0085, -4.7737]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.7737, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0296, -3.5343]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0296, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.0415, -0.1391]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(2.0415, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.1891e+00, -1.0216e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0437, -3.1517]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0437, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0182, -4.0179]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.0179, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.0766, -0.0171]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(4.0766, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.5068e+00, -5.4952e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0869, -2.4857]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0869, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.8406e+00, -3.9355e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.2505, -0.0053]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0053, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.6434e+00, -6.4848e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(6.4848e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.1898, -0.0421]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.1898, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0559, -2.9120]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0559, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.1279e+01, -1.2636e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.2636e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.1426e-04, -7.5731e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.5176, -0.9062]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.9062, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0520, -0.4296]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.0520, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.3860e+00, -2.2802e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(8.3860, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0164, -4.1184]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.1184, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.3742, -0.0348]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.3742, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.3915, -0.2860]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.3915, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.4967, -0.9379]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.4967, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.9327e-03, -6.2498e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(6.2498, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.0442, -0.1387]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(2.0442, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.3883, -1.1338]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.3883, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0173, -4.0665]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0173, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.6829e-03, -5.3662e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0047, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.0713, -0.0475]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0475, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2220, -1.6139]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.6139, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.4719e+00, -7.7006e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(7.7006e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0698, -2.6970]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.6970, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.1682e-05, -1.1356e+01]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.1682e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.3118, -1.3173]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.3173, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.6949e+00, -1.2381e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.2536e-04, -7.2293e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.6296e-03, -5.9422e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.8180e+00, -1.0945e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.8820e-03, -5.5534e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0039, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2487, -1.5134]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.5134, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.1850, -0.3649]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.3649, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.8739, -0.1667]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.8739, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0092, -4.6908]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0092, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1780, -1.8137]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.8137, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.1432, -0.0059]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(5.1432, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.1284, -0.1267]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1267, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0057, -5.1655]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0057, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.4807e-03, -5.4102e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0045, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0136, -4.3056]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.3056, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2690, -1.4445]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.4445, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.4122, -1.0853]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.0853, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.7849e+00, -5.6265e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(5.6265e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.6688e-04, -8.6985e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.2007, -0.1174]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1174, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.8082, -0.0224]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.8082, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.2628e-03, -6.6750e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(6.6750, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.9706, -0.1501]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.9706, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0057, -5.1641]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0057, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.8044e+00, -1.1095e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.5448e-04, -8.7756e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.8411e-05, -9.7483e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(9.7483, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.9749, -0.0069]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0069, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.5379, -0.8770]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.5379, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0530, -2.9638]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0530, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0071, -4.9578]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0071, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0097, -4.6414]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0097, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.4976e+00, -1.5083e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.8485, -0.0079]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0079, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.5601, -0.0288]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0288, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.7660e+00, -1.1529e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.4130, -0.0122]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0122, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0746e+01, -2.1577e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.1577e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.4512e-03, -6.0124e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.5418e-03, -5.3967e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(5.3967, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.6918e-04, -7.4716e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.2260, -0.0054]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0054, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.7973e-03, -6.3224e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0772, -2.6000]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0772, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.1378e-05, -9.8773e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(5.1378e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.7315, -0.6562]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.7315, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2051, -1.6853]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.6853, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.5285e-05, -1.0250e+01]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.5285e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.9023e-04, -8.1448e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.3850e-03, -6.5828e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0094, -4.6770]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.6770, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0196, -3.9411]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0196, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2551, -1.4910]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.2551, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.3395, -1.2453]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.2453, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.5779, -0.2312]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.2312, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0884e-03, -6.8236e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2111, -1.6590]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.2111, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.6617e+00, -1.2797e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.0548e-03, -5.7926e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0031, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0072, -4.9432]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0072, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.4456e+00, -2.1491e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.3711, -1.1711]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.1711, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0190, -3.9716]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.9716, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0134, -4.3219]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.3219, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.9638, -0.4804]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.4804, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.5019e-03, -5.4055e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(5.4055, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.6282, -0.7626]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.6282, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1061, -2.2960]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1061, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.2906, -0.1067]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1067, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.8029, -0.0226]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.8029, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.9453e-03, -5.5372e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(5.5372, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.8381, -0.1733]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1733, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.4508, -1.0137]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.4508, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.6147, -0.0100]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0100, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0609, -2.8295]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0609, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.9611e-03, -5.3086e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0050, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.3184e+00, -8.9761e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(8.9761e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.9752, -0.4734]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.9752, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.3174, -0.0134]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0134, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.3357e-03, -6.0606e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.3013, -1.3465]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.3013, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.7266e-03, -6.3625e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.9577e+00, -1.2874e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.1683e-03, -5.7561e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0032, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0995e+01, -1.6808e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.6808e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0057, -5.1634]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0057, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.7203e+00, -1.6330e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.6936e+00, -3.3729e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0034, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.7452e-03, -5.5891e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0037, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.2765e-04, -8.0236e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.9159e+00, -3.6495e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.7975e-04, -8.6237e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.4277e-03, -6.0220e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0257, -3.6738]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0257, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.3266e+01, -1.7881e-06]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.7881e-06, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.0303e+00, -1.1968e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0256, -3.6786]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0256, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.2151e+01, -5.2452e-06]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(5.2452e-06, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.1644e+00, -1.0466e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.9417e+00, -4.8159e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.8159e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0938, -2.4136]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.4136, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.9248e-03, -6.2539e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1267, -2.1283]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1267, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.3918, -1.1266]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.3918, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0830, -2.5300]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.5300, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.3929e-03, -5.4300e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0044, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.3370e+00, -2.3946e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0388, -3.2696]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.2696, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.8544, -0.0593]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(2.8544, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2414, -1.5396]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.2414, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.2594e-03, -6.0938e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.1115e+01, -1.4901e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.4901e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0088, -4.7368]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.7368, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.5922e+00, -5.0449e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.4184, -1.0731]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.0731, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0852, -2.5046]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0852, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.1065e+00, -3.0155e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.1398e+00, -2.1577e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0472, -3.0764]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0472, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.5945, -0.2269]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.2269, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.9888, -0.1472]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1472, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1370, -2.0552]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.0552, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0463, -3.0956]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0463, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.5295e-03, -6.4836e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0505, -3.0103]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0505, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.2075e-03, -6.1170e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.2503e-03, -5.7306e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0033, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0487e-03, -6.8607e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.7060e+00, -3.3316e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0033, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0995, -2.3573]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.3573, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0519, -2.9846]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.9846, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.7360e+00, -4.3693e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(7.7360, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.9307, -0.0198]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.9307, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.9737, -0.1496]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.9737, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.3461e+00, -4.7783e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(5.3461, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.1719, -0.0057]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0057, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2241, -1.6057]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.6057, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.1284e+00, -2.9512e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.7203, -0.6668]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.7203, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.7472e-04, -7.8894e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(7.8894, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0063, -5.0677]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0063, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.4626, -0.9934]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.4626, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.0601e+00, -3.1597e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.7267, -0.0244]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0244, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.7622, -0.0235]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0235, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2970, -1.3589]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.3589, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.2830, -0.3246]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.3246, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.2991, -0.1058]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1058, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.3370, -0.0362]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.3370, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.4398, -0.0912]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0912, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.2826e-03, -6.0836e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(6.0836, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.1647, -0.0157]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0157, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0521e+01, -2.6941e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.6941e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.5274, -0.2448]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.5274, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.1717e-03, -5.7551e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0032, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0076, -4.8831]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0076, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0106, -4.5498]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0106, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0102, -4.5919]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.5919, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.0979, -0.1309]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1309, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.8152e-04, -7.8716e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.1082e+01, -1.5378e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.5378e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.4693, -0.2615]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.2615, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.4450, -0.2689]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.4450, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.2138, -0.0055]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0055, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.4888e-04, -7.3405e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.7103e-04, -7.8994e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.3675e+00, -8.5469e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(8.5469e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.8205e+00, -1.4769e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.6402e-04, -8.7155e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.2339, -0.1133]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1133, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.8030e+00, -5.5312e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(9.8030, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1001, -2.3514]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.3514, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.0549e+00, -1.1682e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0285, -3.5710]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0285, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.3032, -1.3412]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.3412, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0363, -3.3352]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.3352, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.1250, -0.3925]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.3925, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.9981, -0.1457]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.9981, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.8702e+00, -5.1735e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(5.1735e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.5045, -0.9258]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.9258, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1357, -2.0647]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1357, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.3055, -1.3347]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.3347, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0351, -3.3683]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0351, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.9699, -0.1502]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1502, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.4405, -0.2702]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(1.4405, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0676, -2.7279]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0676, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.3747e+00, -2.3064e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(8.3747, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.9386, -0.4962]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.4962, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.8815, -0.0208]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.8815, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0095, -4.6576]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0095, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.4001, -0.0951]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0951, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.0746e-03, -5.5050e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0041, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.6189e+00, -1.3358e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1881, -1.7635]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1881, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0499, -3.0223]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0499, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.5178, -0.9059]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.5178, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.3537e+00, -4.7421e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0047, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.3117, -0.1044]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(2.3117, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.0648e+00, -1.1563e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.9620e-04, -8.5366e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(8.5366, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0519, -2.9841]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0519, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.4195, -0.0333]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0333, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.3290e-04, -8.0079e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(8.0079, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.5133, -0.9125]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.9125, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2877, -1.3862]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.1478, -0.0058]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0058, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.9707e+00, -9.3940e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.8327, -0.5707]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.5707, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.4694e+00, -2.0979e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(8.4694, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.9170, -0.1590]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1590, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0505, -3.0105]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.0105, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.5485, -0.0106]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0106, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.3386, -1.2474]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.2474, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.9470, -0.0195]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.9470, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.5966e-03, -5.6296e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0036, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2822, -1.4028]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.2822, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.0325e+00, -2.4023e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.0751, -0.0063]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0063, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.0937, -0.0168]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0168, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0271, -3.6203]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0271, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.6251, -0.7662]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.7662, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0990, -2.3617]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0990, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0053, -5.2344]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0053, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.6156e+00, -4.9281e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0148, -4.2179]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0148, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.7837e+00, -1.1327e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0359, -3.3440]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0359, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.3519, -1.2151]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.2151, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.9020, -0.5205]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.5205, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.0591, -0.0481]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.0591, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0536, -2.9522]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0536, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.3817e-03, -5.4325e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0044, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.6164e+00, -1.8118e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0273, -3.6159]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(3.6159, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.7149, -0.1984]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1984, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0077, -4.8708]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0077, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0187, -3.9910]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0187, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.6040e+00, -1.3558e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.1374e+00, -2.1630e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0065, -5.0324]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0065, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.5220e+00, -5.4118e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.8688e+00, -1.0403e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1789, -1.8090]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.1789, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.6830e+00, -4.6076e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(7.6830, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.7351, -0.0242]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0242, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0092, -4.6980]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.6980, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.4066, -0.0337]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0337, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.2494, -0.0053]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0053, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0254, -3.6864]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0254, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.8047, -0.0225]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0225, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.6987, -0.6876]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.6987, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2746, -1.4265]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.4265, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0702e+01, -2.2530e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.2530e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.7676e-03, -5.3483e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0048, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.6651e+00, -1.7248e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.9814e-03, -5.8169e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0030, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.4627, -0.9931]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.4627, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.4421e+00, -2.1563e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.1112e-03, -5.2789e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(5.2789, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.3916, -0.0342]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0342, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.1384e+00, -2.9214e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.4442, -0.2691]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.2691, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0290, -3.5560]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0290, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.9606e+00, -9.4905e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.9606e+00, -4.7206e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(4.7206e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-8.3135e+00, -2.4518e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.6246, -0.0270]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0270, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0080, -4.8307]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0080, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.6161e-03, -5.9474e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.5917, -0.0102]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0102, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.3753e-03, -6.5897e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0537, -2.9516]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0537, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.3833, -1.1444]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.1444, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.6834, -0.7030]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.6834, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.8906e+00, -3.7437e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.0290e-03, -6.8797e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-6.7150e+00, -1.2134e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(6.7150, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.3563e+00, -6.3876e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.3773, -0.2907]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.2907, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.5582e+00, -3.8631e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(5.5582, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.5225e+00, -4.0040e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0040, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.9634e-03, -5.5326e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(5.5326, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.4599, -0.9980]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.4599, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0251, -3.6956]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0251, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0572, -2.8905]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0572, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.5850, -0.8144]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.5850, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.1071, -2.2875]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(2.2875, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.1281, -0.0448]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.1281, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-9.5611e+00, -7.0450e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(7.0450e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.8863, -0.0076]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0076, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.5502, -0.0106]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0106, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.8926, -0.5269]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.8926, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.2891e+00, -5.0589e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0051, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.1480e+01, -1.0371e-05]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(1.0371e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0219, -3.8308]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0219, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.6024, -0.0101]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(4.6024, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0072, -4.9325]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0072, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.6402e-04, -8.7160e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-5.3414e+00, -4.8005e-03]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0048, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-7.1167e+00, -8.1172e-04]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.9639e-03, -5.3080e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(5.3080, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.3366, -0.1016]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1016, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.5652, -0.0287]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(3.5652, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.8946, -0.0569]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(2.8946, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.9202e-04, -8.1390e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-4.1801e-03, -5.4795e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(5.4795, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.5740e-03, -5.9636e+00]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-1.9754, -0.1493]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.1493, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.0116, -4.4645]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.0116, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-3.9419, -0.0196]], grad_fn=<LogSoftmaxBackward0>) tensor([1])\n",
      "tensor(0.0196, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[-0.2951, -1.3645]], grad_fn=<LogSoftmaxBackward0>) tensor([0])\n",
      "tensor(0.2951, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[83], line 9\u001B[0m\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;28mprint\u001B[39m(loss)\n\u001B[0;32m      8\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m----> 9\u001B[0m     \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mepoch:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m,loss:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss\u001B[38;5;241m.\u001B[39mitem()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32mE:\\condaenvs\\pytorch\\lib\\site-packages\\torch\\_tensor.py:525\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    515\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    517\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    518\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    523\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    524\u001B[0m     )\n\u001B[1;32m--> 525\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    526\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    527\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\condaenvs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py:267\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    262\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    264\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    265\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    266\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 267\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    272\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    273\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    274\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    275\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\condaenvs\\pytorch\\lib\\site-packages\\torch\\autograd\\graph.py:744\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    742\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    743\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 744\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    745\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[0;32m    746\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    747\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    748\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "92cb612b8aabb9df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, \n",
    " shuffle=True)"
   ],
   "id": "3259756be16f5e5b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
